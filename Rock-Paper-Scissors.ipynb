{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37b89eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from PIL import Image\n",
    "import os, shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eff41fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=\"./rps-cv-images\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67ca93",
   "metadata": {},
   "source": [
    "#### removing corrupted_images\n",
    "for category in os.listdir(folder_path):\n",
    "\n",
    "*  It loops through each subfolder in the main folder (e.g., rock, paper, scissors).\n",
    "\n",
    "for img_file in os.listdir(category_path):\n",
    "\n",
    "*  It then loops through every image in that subfolder.\n",
    "\n",
    "img = Image.open(img_path)\n",
    "\n",
    "*  Tries to open the image using Pillow (PIL). This checks if the image can be read.\n",
    "\n",
    "img.verify()\n",
    "\n",
    "*  This verifies the image is not corrupted or partially downloaded. It does not load the image into memory (it’s lightweight).\n",
    "\n",
    "If it fails (IOError or SyntaxError)\n",
    "\n",
    "*   That means the image is likely corrupted (damaged file, wrong format, etc.).\n",
    "\n",
    "*   It prints the path of the bad image and deletes it using os.remove(img_path)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7f1a3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_corrupted_images(image_path):\n",
    "    for category in os.listdir(image_path):\n",
    "        category_path = os.path.join(image_path, category)\n",
    "        for img_file in os.listdir(category_path):\n",
    "            img_path = os.path.join(category_path, img_file)\n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                img.verify()\n",
    "            except (IOError, SyntaxError) as e:\n",
    "                print(\"Removing corrupted image:\", img_path)\n",
    "                os.remove(img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17d15383",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_corrupted_images(\"rps-cv-images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec1f29a",
   "metadata": {},
   "source": [
    "#### Loading the data \n",
    "Load all the images (rock, paper, scissors) from folders, resize them to 64×64 pixels, normalize their pixel values, automatically assign labels based on folder names, and split them into training and validation sets.\n",
    "rescale=1./255 → Scales image pixel values from range [0, 255] to [0, 1] (which helps the neural network train better).\n",
    "validation_split=0.2 → Splits your dataset: 80% for training, 20% for validation\n",
    "##### loading the training data \n",
    "'rps-cv-images' → Path to the main folder that contains the rock/, paper/, and scissors/ folders.\n",
    "target_size=(64, 64) → Resizes all images to 64×64 pixels.\n",
    "batch_size=32 → Loads 32 images at a time (good for memory efficiency).\n",
    "class_mode='categorical' → Labels are one-hot encoded. So if the classes are rock, paper, scissors, each image label looks like:\n",
    "\n",
    "Rock → [1, 0, 0]\n",
    "\n",
    "Paper → [0, 1, 0]\n",
    "\n",
    "Scissors → [0, 0, 1]\n",
    "subset='training' → This line tells it to use 80% of the data for training (from the split defined above).\n",
    "\n",
    "##### loading the validation data \n",
    "It uses the remaining 20% of images (subset='validation')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdb01a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1751 images belonging to 3 classes.\n",
      "Found 437 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    image_path,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\",\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    image_path,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7cd19b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = 'rps-cv-images'\n",
    "dst = 'rps-split'\n",
    "splits = ['train', 'val', 'test']\n",
    "\n",
    "for label in os.listdir(src):\n",
    "    files = os.listdir(os.path.join(src, label))\n",
    "    train, temp = train_test_split(files, test_size=0.3, random_state=42)\n",
    "    val, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "    \n",
    "    for split, split_list in zip(splits, [train, val, test]):\n",
    "        os.makedirs(os.path.join(dst, split, label), exist_ok=True)\n",
    "        for f in split_list:\n",
    "            shutil.copy(\n",
    "                os.path.join(src, label, f),\n",
    "                os.path.join(dst, split, label, f)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f39c430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1531 images belonging to 3 classes.\n",
      "Found 328 images belonging to 3 classes.\n",
      "Found 329 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = datagen.flow_from_directory('rps-split/train', target_size=(64, 64), class_mode='categorical')\n",
    "val_gen = datagen.flow_from_directory('rps-split/val', target_size=(64, 64), class_mode='categorical')\n",
    "test_gen = datagen.flow_from_directory('rps-split/test', target_size=(64, 64), class_mode='categorical', shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5455476",
   "metadata": {},
   "source": [
    "cnn model in PyTorch This model will be fixed and used for all optimizer experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)  # Assuming input is 64x64 → after pooling 2x: 16x16\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 3)  # 3 output classes (rock, paper, scissors)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = x.view(-1, 64 * 16 * 16)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rock-paper-scissor)",
   "language": "python",
   "name": "rock-paper-scissor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
